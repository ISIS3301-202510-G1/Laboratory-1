{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "b8cf01ab2dafa068"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import Final\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import nltk\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame, Series\n",
    "from rich.console import Console\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ydata_profiling import ProfileReport"
   ],
   "id": "300f92f24846c8ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Environment Setup",
   "id": "d1c83f46878b3201"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "GITHOME: Final[str] = \"https://raw.githubusercontent.com/ISIS3301-202510-G1/Laboratory-1/refs/heads/main/data/\"",
   "id": "96da42f45563eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "console: Console = Console(width=120)",
   "id": "ddb94d8f5904ead1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Loading Data",
   "id": "166f288c3b44a169"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Attempt to load datasets from the online source\n",
    "try:\n",
    "    # Load testing and training datasets from the specified URL\n",
    "    testing: DataFrame = pandas.read_csv(os.path.join(GITHOME, \"data/test-data.csv\"))\n",
    "    training: DataFrame = pandas.read_csv(os.path.join(GITHOME, \"data/train-data.csv\"))\n",
    "# Fallback to local files if an HTTP error occurs\n",
    "except HTTPError as error:\n",
    "    console.log(\"Online dataset could not be retrieved. Falling back to local files.\")\n",
    "    testing: DataFrame = pandas.read_csv(\"data/test-dataset.csv\")\n",
    "    training: DataFrame = pandas.read_csv(\"data/train-dataset.csv\")"
   ],
   "id": "479593172704f125",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Confirm successful loading of datasets\n",
    "console.log(\"Testing and training datasets successfully loaded!\")"
   ],
   "id": "7c4461133b7310ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validate that both datasets are loaded and contain data\n",
    "assert not testing.empty and not training.empty, \"Error: One or both datasets are empty!\"\n",
    "console.log(\"Dataset validation passed. Both datasets are loaded and non-empty.\")"
   ],
   "id": "75fb8c9ee4a9a1b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display datasets to confirm successful loading\n",
    "# At this stage, only confirm the data is available without further inspection\n",
    "console.log(\"Preview of datasets loaded:\")"
   ],
   "id": "5ee2bd279899df60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "console.log(\"Testing dataset:\")\n",
    "testing  # Shows the dataset object for basic confirmation"
   ],
   "id": "1f9f07435e94931a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "console.log(\"Training dataset:\")\n",
    "training  # Shows the dataset object for basic confirmation"
   ],
   "id": "2599f7d002c45bd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Data Understanding",
   "id": "64ee800f7782a3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# ProfileReport(training)",
   "id": "cd668903b2140e7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1. Dataset Overview",
   "id": "7c81f3339855b6cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "training.info()",
   "id": "1545635cadaa1a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "training.describe()",
   "id": "64ba2f576e21eff5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "training.head()",
   "id": "c7748a21585949b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 Data Quality Check",
   "id": "1471b30425686b7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize a list to collect error messages\n",
    "errors: list[str] = []\n",
    "\n",
    "# Validate constraints\n",
    "invalid: Series  # Define `invalid` as a Series for consistency\n",
    "\n",
    "# ra: 0 <= ra <= 360\n",
    "if not (invalid := training[(training['ra'] < 0) | (training['ra'] > 360)]).empty:\n",
    "    errors.append(f\"Column 'ra' contains values outside the range [0, 360]. Invalid rows: {invalid[['ra']].values.tolist()}\")\n",
    "\n",
    "# dec: -90 <= dec <= 90\n",
    "if not (invalid := training[(training['dec'] < -90) | (training['dec'] > 90)]).empty:\n",
    "    errors.append(f\"Column 'dec' contains values outside the range [-90, 90]. Invalid rows: {invalid[['dec']].values.tolist()}\")\n",
    "\n",
    "# Magnitudes (u, g, r, i, z): > 0\n",
    "for feature in ('u', 'g', 'r', 'i', 'z'):\n",
    "    if not (invalid := training[training[feature] <= 0]).empty:\n",
    "        errors.append(f\"Column '{feature}' contains non-positive values. Invalid rows: {invalid[[feature]].values.tolist()}\")\n",
    "\n",
    "# run: dtype == int and >= 0\n",
    "if not (invalid := training[training['run'] < 0]).empty:\n",
    "    errors.append(f\"Column 'run' contains negative values. Invalid rows: {invalid[['run']].values.tolist()}\")\n",
    "if training['run'].dtype != int:\n",
    "    errors.append(f\"Column 'run' is not of type integer.\")\n",
    "\n",
    "# camcol: Valid values {1, 2, 3, 4, 5, 6}\n",
    "if not (invalid := training[~training['camcol'].isin({1, 2, 3, 4, 5, 6})]).empty:\n",
    "    errors.append(f\"Column 'camcol' contains invalid values. Invalid rows: {invalid[['camcol']].values.tolist()}\")\n",
    "\n",
    "# field: > 0\n",
    "if not (invalid := training[training['field'] < 1]).empty:\n",
    "    errors.append(f\"Column 'field' contains invalid values. Invalid rows: {invalid[['field']].values.tolist()}\")\n",
    "\n",
    "# score: 0 <= score <= 1\n",
    "if not (invalid := training[(training['score'] < 0) | (training['score'] > 1)]).empty:\n",
    "    errors.append(f\"Column 'score' contains invalid values. Invalid rows: {invalid[['score']].values.tolist()}\")\n",
    "\n",
    "# clean: Valid values {0, 1}\n",
    "if not (invalid := training[~training['clean'].isin({0, 1})]).empty:\n",
    "    errors.append(f\"Column 'clean' contains invalid values. Invalid rows: {invalid[['clean']].values.tolist()}\")\n",
    "\n",
    "# class: Valid values {\"STAR\", \"GALAXY\", \"QSO\"}\n",
    "if not (invalid := training[~training['class'].isin({\"STAR\", \"GALAXY\", \"QSO\"})]).empty:\n",
    "    errors.append(f\"Column 'class' contains invalid values. Invalid rows: {invalid[['class']].values.tolist()}\")\n",
    "\n",
    "# redshift: Must be numeric\n",
    "if training['redshift'].isnull().any():\n",
    "    errors.append(f\"Column 'redshift' contains missing values.\")\n",
    "\n",
    "# mjd: > 0\n",
    "if not (invalid := training[training['mjd'] <= 0]).empty:\n",
    "    errors.append(f\"Column 'mjd' contains non-positive values. Invalid rows: {invalid[['mjd']].values.tolist()}\")\n",
    "\n",
    "# rowv and colv: Must be numeric\n",
    "for feature in ('rowv', 'colv'):\n",
    "    if training[feature].isnull().any():\n",
    "        errors.append(f\"Column '{feature}' contains missing values.\")\n",
    "\n",
    "# Log all errors\n",
    "if errors:\n",
    "    console.log(\"Data validation issues found:\")\n",
    "    console.log(*map(\"- {}\".format, errors), sep=\"\\n\")\n",
    "else:\n",
    "    console.log(\"All data validation checks passed successfully.\")\n"
   ],
   "id": "1dbae0186559917e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3. Exploratory Data Analysis",
   "id": "27327afec47866fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3.1. Numerical Features Analysis",
   "id": "b200f52c572cd1f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# List of numerical features\n",
    "numerical: list[str] = [\"ra\", \"dec\", \"u\", \"g\", \"r\", \"i\", \"z\", \"redshift\", \"mjd\", \"rowv\", \"colv\"]\n",
    "\n",
    "# Visualize distributions\n",
    "for feature in numerical:\n",
    "    pyplot.figure(figsize=(8, 4))\n",
    "    seaborn.histplot(training[feature], kde=True)\n",
    "    pyplot.title(f'Distribution of {feature}')\n",
    "    pyplot.xlabel(feature)\n",
    "    pyplot.ylabel('Frequency')\n",
    "    pyplot.show()"
   ],
   "id": "9fe29d054d38ef11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3.2. Categorical Features Analysis",
   "id": "5b1d8d2df4caf65b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Bar plot for 'class'\n",
    "pyplot.figure(figsize=(8, 4))\n",
    "seaborn.countplot(data=training, x='class', order=training['class'].value_counts().index)\n",
    "pyplot.title('Frequency Distribution of Class')\n",
    "pyplot.xlabel('Class')\n",
    "pyplot.ylabel('Count')\n",
    "pyplot.show()\n",
    "\n",
    "# Bar plot for 'clean'\n",
    "pyplot.figure(figsize=(8, 4))\n",
    "seaborn.countplot(data=training, x='clean')\n",
    "pyplot.title('Frequency Distribution of Clean')\n",
    "pyplot.xlabel('Clean')\n",
    "pyplot.ylabel('Count')\n",
    "pyplot.show()\n"
   ],
   "id": "f5318d26958c254",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3.3. Target Variable Analysis",
   "id": "47832651d3b1af4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distribution of redshift\n",
    "pyplot.figure(figsize=(8, 4))\n",
    "seaborn.histplot(training['redshift'], kde=True, bins=30)\n",
    "pyplot.title('Distribution of Redshift')\n",
    "pyplot.xlabel('Redshift')\n",
    "pyplot.ylabel('Frequency')\n",
    "pyplot.show()"
   ],
   "id": "bbf5564e174837d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3.4. Relationships Between Features",
   "id": "f239631a4e5478ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correlation matrix for numerical features\n",
    "correlations: DataFrame = training[numerical].corr()\n",
    "\n",
    "# Visualize the correlation matrix as a heatmap\n",
    "pyplot.figure(figsize=(10, 8))\n",
    "seaborn.heatmap(correlations, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "pyplot.title('Correlation Matrix')\n",
    "pyplot.show()"
   ],
   "id": "1379f228ddbf6170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Scatter plot of redshift vs selected features\n",
    "for feature in ['u', 'g', 'r', 'i', 'z']:\n",
    "    pyplot.figure(figsize=(8, 4))\n",
    "    seaborn.scatterplot(data=training, x=feature, y='redshift')\n",
    "    pyplot.title(f'Relationship between {feature} and Redshift')\n",
    "    pyplot.xlabel(feature)\n",
    "    pyplot.ylabel('Redshift')\n",
    "    pyplot.show()"
   ],
   "id": "cb272bd61364b7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Box plot for 'redshift' grouped by 'class'\n",
    "pyplot.figure(figsize=(10, 6))\n",
    "seaborn.boxplot(data=training, x='class', y='redshift')\n",
    "pyplot.title('Box Plot of Redshift by Class')\n",
    "pyplot.xlabel('Class')\n",
    "pyplot.ylabel('Redshift')\n",
    "pyplot.show()"
   ],
   "id": "ecce9edc36e77a6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Box plot for 'redshift' grouped by 'clean'\n",
    "pyplot.figure(figsize=(8, 4))\n",
    "seaborn.boxplot(data=training, x='clean', y='redshift')\n",
    "pyplot.title('Box Plot of Redshift by Clean Flag')\n",
    "pyplot.xlabel('Clean')\n",
    "pyplot.ylabel('Redshift')\n",
    "pyplot.show()"
   ],
   "id": "94a0564f60b09b57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Data Preparation",
   "id": "acbec399b7b6dbca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 Removing Unnecessary Features",
   "id": "810e1ca763968825"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unnecessary: list[str] = ['objid', 'run', 'camcol', 'field', 'mjd']\n",
    "training.drop(columns=unnecessary, inplace=True)"
   ],
   "id": "c79a0e88c415ad68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2. Cleaning and Encoding Categorical Features",
   "id": "8e90cfe7dfb3e0f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Clean the 'class' column (categorical feature)\n",
    "training['class'] = training['class'].apply(lambda x: min({\"STAR\", \"GALAXY\", \"QSO\"}, key=lambda category: nltk.edit_distance(x, category)))\n",
    "# One-hot encode the 'class' column\n",
    "training = pandas.get_dummies(training, columns=['class'])"
   ],
   "id": "1fd4ec270fdd46c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.3. Transforming Binary Features",
   "id": "5d331ceffa38503c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert 'clean' column to boolean (True/False)\n",
    "training['clean'] = training['clean'].astype(bool)"
   ],
   "id": "45be1a77cdac7f82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.4. Feature Selection Based on Correlation",
   "id": "3a6fb9c9adbcb9bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set a correlation threshold\n",
    "threshold: float = 0.5\n",
    "\n",
    "# Calculate correlations with the target ('redshift')\n",
    "correlations: DataFrame = training.corr()\n",
    "\n",
    "# Select features with absolute correlation > threshold\n",
    "targets: Series[float] = correlations['redshift'].abs()\n",
    "features: Series[str] = targets[targets > threshold].index\n",
    "\n",
    "# Keep only the selected features and the target\n",
    "training = training[features]"
   ],
   "id": "d765ad65fc808748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.5. Normalizing Numeric Features",
   "id": "4661d2fdab7ff319"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify numeric features to normalize\n",
    "numerics: list[str] = list({'u', 'g', 'r', 'i', 'z', 'rowv', 'colv'} & set(training.columns))\n",
    "\n",
    "# Initialize scaler\n",
    "scaler: StandardScaler = StandardScaler()\n",
    "\n",
    "# Apply scaling\n",
    "training[numerics] = scaler.fit_transform(training[numerics])"
   ],
   "id": "5c0a962ecac835ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.6. Handling Outliers",
   "id": "9e4e8d8e08832d49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sanitize(dataset: DataFrame, columns: list[str]) -> DataFrame:\n",
    "    for col in columns:\n",
    "        q1: float = dataset[col].quantile(0.25)\n",
    "        q3: float = dataset[col].quantile(0.75)\n",
    "        iqr: float = q3 - q1\n",
    "        lower_bound: float = q1 - 1.5 * iqr\n",
    "        upper_bound: float = q3 + 1.5 * iqr\n",
    "        # Keep only rows within bounds\n",
    "        dataset = dataset[(dataset[col] >= lower_bound) & (dataset[col] <= upper_bound)]\n",
    "    return dataset\n",
    "\n",
    "# Identify numeric columns for outlier handling\n",
    "numerics: list[str] = list({'u', 'g', 'r', 'i', 'z', 'rowv', 'colv'} & set(training.columns))\n",
    "\n",
    "# Remove outliers\n",
    "training = sanitize(training, numerics)\n"
   ],
   "id": "3a1be0d65dacf66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.7. Transforming Skewed Features",
   "id": "4af29812499e172"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate skewness for numeric features\n",
    "features: Series[str] = training[numerics].skew().sort_values(ascending=False)\n",
    "\n",
    "# Identify skewed features with skewness > |0.5|\n",
    "columns: list[str] = features[features.abs() > 0.5].index.tolist()\n",
    "\n",
    "# Apply `log1p` transformation to reduce skewness\n",
    "for feature in columns:\n",
    "    if (training[feature] > 0).all():\n",
    "        training[feature] = numpy.log1p(training[feature])\n",
    "    else:\n",
    "        console.log(f\"Skipping transformation for {feature} due to non-positive values.\")\n"
   ],
   "id": "bf357e6ffcbfc64d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.8. Splitting the Data",
   "id": "1068c60b801af02c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x: DataFrame = training.drop(columns=['redshift'])\n",
    "y: Series[float] = training['redshift']\n",
    "\n",
    "x_train: DataFrame\n",
    "y_train: Series[float]\n",
    "x_test: DataFrame\n",
    "y_test: Series[float]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "console.log(f\"Training Features Shape: {x_train.shape}\")\n",
    "console.log(f\"Training Target Shape: {y_train.shape}\")\n",
    "console.log(f\"Test Features Shape: {x_test.shape}\")\n",
    "console.log(f\"Test Target Shape: {y_test.shape}\")"
   ],
   "id": "eeb76c98388f1677",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Modeling",
   "id": "c4f15cf11ab96ccf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ModelSelector:\n",
    "    def __init__(self) -> None:\n",
    "        # Optimized model initialization\n",
    "        self._models: dict[str, LinearRegression | Ridge | RidgeCV | SGDRegressor] = {\n",
    "            # Linear Regression (default, no hyperparameters to tune here)\n",
    "            'linear-regression': LinearRegression(),\n",
    "\n",
    "            # Ridge Regression with an optimized regularization strength\n",
    "            'ridge': Ridge(alpha=1.0, solver='auto', random_state=42),\n",
    "\n",
    "            # Ridge Cross-Validation to select the best alpha (regularization strength)\n",
    "            'ridge-cv': RidgeCV(alphas=[0.1, 1.0, 10.0], cv=5, scoring='neg_mean_squared_error'),\n",
    "\n",
    "            # Stochastic Gradient Descent Regressor with adjusted parameters\n",
    "            'sgd-regressor': SGDRegressor(\n",
    "                max_iter=1000,  # Sufficient iterations for convergence\n",
    "                tol=1e-3,       # Stopping criterion\n",
    "                penalty='l2',   # L2 regularization (ridge-like behavior)\n",
    "                eta0=0.01,      # Lower initial learning rate\n",
    "                learning_rate='adaptive',  # Adjust learning rate during training\n",
    "                random_state=42\n",
    "            )\n",
    "        }\n",
    "\n",
    "        self._metrics: dict[str, dict[str, float]] = {\n",
    "            'linear-regression': {},\n",
    "            'ridge': {},\n",
    "            'ridge-cv': {},\n",
    "            'sgd-regressor': {}\n",
    "        }\n",
    "\n",
    "    def fit(self, x: DataFrame, y: Series) -> None:\n",
    "        for name, model in self._models.items():\n",
    "            model.fit(x, y)\n",
    "\n",
    "    def test(self, x: DataFrame, y: Series) -> None:\n",
    "        for name, model in self._models.items():\n",
    "            # Generate predictions\n",
    "            prediction: Series = model.predict(x)\n",
    "\n",
    "            # Calculate metrics\n",
    "            mse: float = mean_squared_error(y, prediction)\n",
    "            rmse: float = mse ** 0.5\n",
    "            r2: float = r2_score(y, prediction)\n",
    "\n",
    "            # Store metrics\n",
    "            self._metrics[name]['MSE'] = mse\n",
    "            self._metrics[name]['RMSE'] = rmse\n",
    "            self._metrics[name]['RÂ²'] = r2\n",
    "\n",
    "\n",
    "selector: ModelSelector = ModelSelector()\n",
    "selector.fit(x_train, y_train)\n",
    "selector.test(x_test, y_test)\n",
    "print(selector._metrics)"
   ],
   "id": "8e44d5a9d5ce6905",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dfa118df36a7a075",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
